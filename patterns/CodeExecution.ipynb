{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reference:https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/code-execution-groupchat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "from autogen_core import DefaultTopicId, MessageContext, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.code_executor import CodeBlock, CodeExecutor\n",
    "from autogen_core.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token provider\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Create the completion client\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    model = \"gpt-4o\",\n",
    "    azure_endpoint=\"https://yourservice.openai.azure.com/\",\n",
    "    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    # api_key=\"sk-...\", # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "\n",
    "@default_subscription\n",
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._chat_history: List[LLMMessage] = [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"Write Python script in markdown block, and it will be executed.\n",
    "Always save figures to file in the current directory. Do not use plt.show(). All code required to complete this task must be contained within a single response.\"\"\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        self._chat_history.append(UserMessage(content=message.content, source=\"user\"))\n",
    "        result = await self._model_client.create(self._chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))  # type: ignore\n",
    "        await self.publish_message(Message(content=result.content), DefaultTopicId())  # type: ignore\n",
    "\n",
    "\n",
    "def extract_markdown_code_blocks(markdown_text: str) -> List[CodeBlock]:\n",
    "    pattern = re.compile(r\"```(?:\\s*([\\w\\+\\-]+))?\\n([\\s\\S]*?)```\")\n",
    "    matches = pattern.findall(markdown_text)\n",
    "    code_blocks: List[CodeBlock] = []\n",
    "    for match in matches:\n",
    "        language = match[0].strip() if match[0] else \"\"\n",
    "        code_content = match[1]\n",
    "        code_blocks.append(CodeBlock(code=code_content, language=language))\n",
    "    return code_blocks\n",
    "\n",
    "\n",
    "@default_subscription\n",
    "class Executor(RoutedAgent):\n",
    "    def __init__(self, code_executor: CodeExecutor) -> None:\n",
    "        super().__init__(\"An executor agent.\")\n",
    "        self._code_executor = code_executor\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        code_blocks = extract_markdown_code_blocks(message.content)\n",
    "        if code_blocks:\n",
    "            result = await self._code_executor.execute_code_blocks(\n",
    "                code_blocks, cancellation_token=ctx.cancellation_token\n",
    "            )\n",
    "            print(f\"\\n{'-'*80}\\nExecutor:\\n{result.output}\")\n",
    "            await self.publish_message(Message(content=result.output), DefaultTopicId())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "\n",
    "work_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create an local embedded runtime.\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "async with DockerCommandLineCodeExecutor(work_dir=work_dir) as executor:  # type: ignore[syntax]\n",
    "    # Register the assistant and executor agents by providing\n",
    "    # their agent types, the factory functions for creating instance and subscriptions.\n",
    "    await Assistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: Assistant(\n",
    "            az_model_client\n",
    "        ),\n",
    "    )\n",
    "    await Executor.register(runtime, \"executor\", lambda: Executor(executor))\n",
    "\n",
    "    # Start the runtime and publish a message to the assistant.\n",
    "    runtime.start()\n",
    "    await runtime.publish_message(\n",
    "        Message(\"Create a plot of NVIDA vs TSLA stock returns YTD from 2024-01-01.\"), DefaultTopicId()\n",
    "    )\n",
    "    await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{work_dir}/nvidia_vs_tesla_ytd_returns.png\")  # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
