{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#reference: https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/sequential-workflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from autogen_core import (\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    TopicId,\n",
    "    TypeSubscription,\n",
    "    message_handler,\n",
    "    type_subscription,\n",
    ")\n",
    "from autogen_core.models import ChatCompletionClient, SystemMessage, UserMessage\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\") # Load environment variables from a .env file\n",
    "\n",
    "azure_ai_service_name = os.getenv(\"AZURE_AI_SERVICE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token provider\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Create the completion client\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    model = \"gpt-4o\",\n",
    "    azure_endpoint=f\"https://{azure_ai_service_name}.openai.azure.com/\",\n",
    "    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    # api_key=\"sk-...\", # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_extractor_topic_type = \"ConceptExtractorAgent\"\n",
    "writer_topic_type = \"WriterAgent\"\n",
    "format_proof_topic_type = \"FormatProofAgent\"\n",
    "user_topic_type = \"User\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=concept_extractor_topic_type)\n",
    "class ConceptExtractorAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A concept extractor agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You are a marketing analyst. Given a product description, identify:\\n\"\n",
    "                \"- Key features\\n\"\n",
    "                \"- Target audience\\n\"\n",
    "                \"- Unique selling points\\n\\n\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_description(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Product description: {message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(writer_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=writer_topic_type)\n",
    "class WriterAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A writer agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You are a marketing copywriter. Given a block of text describing features, audience, and USPs, \"\n",
    "                \"compose a compelling marketing copy (like a newsletter section) that highlights these points. \"\n",
    "                \"Output should be short (around 150 words), output just the copy as a single text block.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_intermediate_text(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Below is the info about the product:\\n\\n{message.content}\"\n",
    "\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(format_proof_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=format_proof_topic_type)\n",
    "class FormatProofAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A format & proof agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You are an editor. Given the draft copy, correct grammar, improve clarity, ensure consistent tone, \"\n",
    "                \"give format and make it polished. Output the final improved copy as a single text block.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_intermediate_text(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Draft copy:\\n{message.content}.\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(user_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=user_topic_type)\n",
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"A user agent that outputs the final copy to the user.\")\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_final_copy(self, message: Message, ctx: MessageContext) -> None:\n",
    "        print(f\"\\n{'-'*80}\\n{self.id.type} received final copy:\\n{message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = az_model_client\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "await ConceptExtractorAgent.register(\n",
    "    runtime, type=concept_extractor_topic_type, factory=lambda: ConceptExtractorAgent(model_client=model_client)\n",
    ")\n",
    "\n",
    "await WriterAgent.register(runtime, type=writer_topic_type, factory=lambda: WriterAgent(model_client=model_client))\n",
    "\n",
    "await FormatProofAgent.register(\n",
    "    runtime, type=format_proof_topic_type, factory=lambda: FormatProofAgent(model_client=model_client)\n",
    ")\n",
    "\n",
    "await UserAgent.register(runtime, type=user_topic_type, factory=lambda: UserAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime.start()\n",
    "\n",
    "await runtime.publish_message(\n",
    "    Message(content=\"An eco-friendly stainless steel water bottle that keeps drinks cold for 24 hours\"),\n",
    "    topic_id=TopicId(concept_extractor_topic_type, source=\"default\"),\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
